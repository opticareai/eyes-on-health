<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>2&nbsp; The Scientific Foundation: What the Evidence Reveals – Eyes on Health</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./3-Chapter-Wellness.html" rel="next">
<link href="./1-Chapter-Intro.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-e26003cea8cd680ca0c55a263523d882.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-5df17783e47628fdd0a009a58fb5d268.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="_resources/book/css/normalize.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./2-Chapter-Science.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">The Scientific Foundation: What the Evidence Reveals</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Eyes on Health</a> 
        <div class="sidebar-tools-main">
    <div class="dropdown">
      <a href="" title="Download" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Download"><i class="bi bi-download"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="./Eyes-on-Health.pdf">
              <i class="bi bi-file-pdf pe-1"></i>
            Download PDF
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="./Eyes-on-Health.epub">
              <i class="bi bi-journal pe-1"></i>
            Download ePub
            </a>
          </li>
      </ul>
    </div>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1-Chapter-Intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">The Eye as a Window: Unveiling the Power of Retinal Imaging</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2-Chapter-Science.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">The Scientific Foundation: What the Evidence Reveals</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3-Chapter-Wellness.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Opticare AI – Marrying Innovation with Wellness</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./4-Chapter-Practical.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Practical Applications in a Wellness Practice</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./5-Chapter-Guidebook.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Step-by-Step Guide to Using the Opticare Camera</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./6-Chapter-Faster.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Technology Moves Faster than Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./7-Chapter-Future.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">The Future of Retinal Imaging and AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./8-Chapter-Beyond.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Beyond the Eye – A Holistic Approach to Health</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./9-Chapter-Skepticism.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Addressing Skepticism and Setting Expectations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-Chapter-Final.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Embracing the Cutting Edge – A Call to Action</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Summary</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#the-retina-a-microcosm-of-the-body" id="toc-the-retina-a-microcosm-of-the-body" class="nav-link active" data-scroll-target="#the-retina-a-microcosm-of-the-body"><span class="header-section-number">2.1</span> The Retina: A Microcosm of the Body</a></li>
  <li><a href="#the-advantage-of-fundus-photography" id="toc-the-advantage-of-fundus-photography" class="nav-link" data-scroll-target="#the-advantage-of-fundus-photography"><span class="header-section-number">2.2</span> The Advantage of Fundus Photography</a></li>
  <li><a href="#deep-learning-artificial-intelligence" id="toc-deep-learning-artificial-intelligence" class="nav-link" data-scroll-target="#deep-learning-artificial-intelligence"><span class="header-section-number">2.3</span> Deep Learning &amp; Artificial Intelligence</a></li>
  <li><a href="#retinal-imaging-cardiovascular-health-a-deep-connection" id="toc-retinal-imaging-cardiovascular-health-a-deep-connection" class="nav-link" data-scroll-target="#retinal-imaging-cardiovascular-health-a-deep-connection"><span class="header-section-number">2.4</span> Retinal Imaging &amp; Cardiovascular Health: A Deep Connection</a></li>
  <li><a href="#retinal-imaging-cerebral-health-a-reflection-of-the-brain" id="toc-retinal-imaging-cerebral-health-a-reflection-of-the-brain" class="nav-link" data-scroll-target="#retinal-imaging-cerebral-health-a-reflection-of-the-brain"><span class="header-section-number">2.5</span> Retinal Imaging &amp; Cerebral Health: A Reflection of the Brain</a></li>
  <li><a href="#retinal-imaging-anemia-visualizing-blood-composition" id="toc-retinal-imaging-anemia-visualizing-blood-composition" class="nav-link" data-scroll-target="#retinal-imaging-anemia-visualizing-blood-composition"><span class="header-section-number">2.6</span> Retinal Imaging &amp; Anemia: Visualizing Blood Composition</a></li>
  <li><a href="#retinal-imaging-for-prediction-of-age-and-mortality-risk" id="toc-retinal-imaging-for-prediction-of-age-and-mortality-risk" class="nav-link" data-scroll-target="#retinal-imaging-for-prediction-of-age-and-mortality-risk"><span class="header-section-number">2.7</span> Retinal Imaging for Prediction of Age and Mortality Risk</a></li>
  <li><a href="#a-growing-body-of-evidence-beyond-the-main-focus" id="toc-a-growing-body-of-evidence-beyond-the-main-focus" class="nav-link" data-scroll-target="#a-growing-body-of-evidence-beyond-the-main-focus"><span class="header-section-number">2.8</span> A Growing Body of Evidence: Beyond The Main Focus</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">The Scientific Foundation: What the Evidence Reveals</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="the-retina-a-microcosm-of-the-body" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="the-retina-a-microcosm-of-the-body"><span class="header-section-number">2.1</span> The Retina: A Microcosm of the Body</h2>
<p>Imagine a window, not to the outside world, but into the very core of your health. This window, remarkably, is not a sophisticated scanning device or an invasive procedure, but a small patch of tissue lining the back of your eye—the retina. For centuries, the retina has been primarily known for its role in vision, translating light into the images we perceive. However, groundbreaking research is now revealing that the retina is more than just a visual organ. It’s a microcosm of your overall health, an accessible and revealing site that offers a unique window into the inner workings of your body. Through the lens of high-resolution fundus photography, we’re now able to unlock a wealth of information beyond just the health of your eyes.</p>
<p>The retina isn’t simply a standalone structure; it’s an extension of your central nervous system, directly connected to your brain via the optic nerve. This direct link means that the health of the retina often reflects what’s happening within the brain, as well as other organs. Like the brain, the retina has a complex layered structure of neural cells that respond to light, generating electrical signals that are then sent to the visual processing centers of the brain. Because of this direct connection to the brain, the retina is also subject to similar degenerative processes as occur in brain diseases, such as Alzheimer’s. Therefore, studying the retina can often provide valuable insights into the health and functional status of the central nervous system.</p>
<p>The retina is also home to a complex network of blood vessels called the “retinal microvasculature.” These microvessels are extraordinarily delicate and uniquely visible within the body without invasive procedures. This is where the eye’s unique structure provides such a powerful opportunity: the transparency of the ocular tissues allows the direct visualization of the retinal microvasculature through non-invasive high-resolution fundus photography. Unlike other areas of the body where similar structures may exist, the microvasculature of the retina is not obscured by skin or muscle; hence, we can examine the condition of these microvessels non-invasively.</p>
<p>The microvasculature is not merely a passive system. These tiny vessels are highly active, constantly regulating blood flow to ensure that the retina receives the optimal amount of oxygen and nutrients for its metabolic needs. Because of this highly active and sensitive nature, the microvasculature is readily impacted by metabolic changes and systemic inflammation. Therefore, this network of blood vessels provides a direct, easily accessible view of how the cardiovascular system responds to stressors and diseases. Moreover, these microvessels provide a unique opportunity to monitor conditions related to the heart, blood and brain in real-time. In addition to oxygen and nutrients, the blood vessels also transport immune cells and other blood components that can contribute to or mediate inflammation. Consequently, observation of retinal blood vessels can also give valuable insights into the state of inflammation of the body.</p>
<p>Further solidifying the idea of the retina as a microcosm, the retina shares embryonic origins, physiological characteristics, and anatomical structures with vital organs like the heart, brain, and kidneys. This shared developmental pathway means that these organs are often affected by similar diseases. For example, the endothelial cells that line the blood vessels in the heart, brain, kidneys and retina are all derived from similar progenitors in the embryo. Consequently, diseases that target endothelial cells, such as cardiovascular disease, can often be observed via changes in the retinal blood vessels. In fact, the study of retinal vascular changes has even helped researchers discover new potential disease mechanisms of systemic disorders.</p>
<p>The significance of this shared origin is that the retina is often subjected to the same degenerative and pathological processes as many other tissues, making it a valuable proxy for what’s happening throughout the body. Thus, the retina may not just reflect the state of one’s eyes, but may also reflect the cumulative effects of overall health over time.</p>
</section>
<section id="the-advantage-of-fundus-photography" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="the-advantage-of-fundus-photography"><span class="header-section-number">2.2</span> The Advantage of Fundus Photography</h2>
<p>While these concepts may be complex, they are made accessible through the use of high-resolution fundus photography. This specialized imaging technique uses a camera with particular optics and light spectrum to capture detailed images of the retina, including the optic disc, blood vessels, and the macula, the area of sharp central vision. These photographs reveal subtle changes not easily visible during a traditional ophthalmoscopy exam (looking into the eyes using a handheld tool). These photos also generate a permanent record of the retina that can be analysed by human and AI.</p>
<p>Through the lens of high-resolution fundus photography, AI can detect a host of changes in the retina that indicate the presence of an underlying condition. These changes may be related to:</p>
<ul>
<li><p><strong>Vessel Caliber</strong>: The diameter of blood vessels (arterioles and venules). Narrowing or widening can be indicators of high blood pressure or inflammation.</p></li>
<li><p><strong>Vessel Tortuosity</strong>: The degree of bending or twisting in blood vessels. Abnormally tortuous vessels can be linked to age or other disease processes.</p></li>
<li><p><strong>Changes in Colour</strong>: Differences in the appearance of the retina related to the blood flow, oxygenation, or the presence of certain pigments.</p></li>
<li><p><strong>Presence of Lesions</strong>: Such as hemorrhages, exudates, and drusen.</p></li>
<li><p><strong>Changes in Retinal Layer Thickness</strong>: Variations in layer thickness have been shown to correlate with a variety of systemic diseases.</p></li>
</ul>
<p>The power of fundus photography as a tool lies in its ability to capture these subtle signals, offering a glimpse into the intricate workings of the body. It reveals information not readily apparent through routine physical exams or blood tests. Often, these subtle retinal changes precede more pronounced systemic symptoms and can therefore act as a warning system, allowing for earlier detection and intervention.</p>
<p>This also highlights the importance of looking beyond the overt signs of disease. Many individuals, especially those interested in wellness and preventive medicine, may not have obvious symptoms of any disease and are considered “healthy”. However, even if a disease is yet to manifest clinically, subclinical or pre-symptomatic stages may be detectable via these subtle changes in retinal morphology.</p>
<p>By studying the retina through high-resolution fundus photography, we are no longer confined to assessing just eye-related health. Instead, this technology allows us to unlock the secrets held within this unique tissue. It enables us to:</p>
<ul>
<li><p>Assess the health of your vascular system</p></li>
<li><p>Determine your likelihood of certain systemic conditions</p></li>
<li><p>Gain insight into your biological age</p></li>
<li><p>Identify potential early signs of disease</p></li>
</ul>
<p>This holistic view, enabled by retinal imaging, moves us away from a purely reactive approach to health and towards a more proactive and personalized model of care. It is a method that acknowledges the interconnectedness of the body’s systems and empowers individuals to take control of their own health and wellbeing.</p>
<p>The retina, once considered solely as an organ of vision, is now recognized as a fascinating and valuable tissue that can be used to assess overall health. High-resolution fundus photography and the power of AI have given us the ability to delve into these secrets to find clues about disease states, and biological aging, opening up a new frontier in the way we understand, monitor and promote health. While research is ongoing, the basic principles and studies outlined in this section clearly demonstrate the amazing potential of this modality to revolutionize wellness and health assessment.</p>
</section>
<section id="deep-learning-artificial-intelligence" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="deep-learning-artificial-intelligence"><span class="header-section-number">2.3</span> Deep Learning &amp; Artificial Intelligence</h2>
<p>The human eye is remarkable in its ability to discern incredibly subtle patterns. However, even the most skilled human eye can’t compete with the power of a computer when it comes to quickly processing and analyzing vast amounts of complex information. This is where deep learning and artificial intelligence (AI) become invaluable tools in the realm of high-resolution fundus photography. To fully appreciate the power of fundus imaging for health assessment, understanding the role of AI is essential.</p>
<p>As we discussed in the previous section, the retina holds a wealth of information about our overall health. However, identifying and interpreting the subtle changes within a retinal image can be challenging. This is where traditional methods have their limitations; relying on human interpretation is not only time-consuming, but it can also be subject to inter- and intra-reader variability (that is, one person might interpret the same photo differently on different occasions, and two people might interpret the same photo differently from each other). With AI, specifically deep learning, these limitations can be overcome.</p>
<p>Traditional computer programs have often relied on “hand-crafted” algorithms. These were built by human engineers, who would pre-program all the steps the program must take, and which features it should look for in the images. Deep learning provides a radical shift, because it is not programmed to follow pre-determined instructions. Instead, a deep learning system is trained on vast amounts of data. For example, instead of telling the AI program how to identify a blood vessel, a deep learning system is trained on hundreds of thousands of retinal images and their corresponding health outcomes, learning the subtle and complex relationships between image patterns and disease states. This process allows AI to detect patterns and features that a human eye might miss, making the diagnostic and predictive capabilities of fundus imaging even more powerful.</p>
<p>Deep learning is a specific type of machine learning (a subfield of AI) that employs artificial neural networks with multiple layers (hence the name “deep”). These layers enable the AI system to process information through hierarchical stages, similar to the complex networks in the brain. In effect, the AI algorithm “learns” what features are relevant for the task at hand, and “decides” on the relative weighting that should be applied to these features. In general, a deep learning model is trained on hundreds of thousands (or even millions) of retinal images with their corresponding ground-truth clinical diagnoses and other health information; thus, each layer in the neural network learns increasingly more abstract and relevant features, ultimately allowing it to perform a task as sophisticated as detecting glaucoma or diabetic retinopathy, or predicting an individual’s biological age.</p>
<p>The advantage of this “deep” architecture is that it enables the AI model to automatically extract higher level and more nuanced characteristics from the images. For example, rather than being programmed to analyze just vessel caliber or vessel tortuosity, AI will automatically learn to assess these factors, and other image features, and then learns how to weigh these factors relative to the health outcomes. This also means that deep learning is capable of extracting new information, even about those underlying factors that may not even be discernable to the human eye, and which might have been missed using standard methods.</p>
<p>Opticare has incorporated this revolutionary technology into an AI-powered fundus camera to provide state-of-the-art health assessments. The Opticare AI system is a deep learning model trained on a massive dataset of over 30 million labeled retinal images. This training enables the system to identify subtle patterns in your retinal images and compare these patterns to known characteristics of different health states.</p>
<p>When you take a fundus photo with your Opticare device, the image is immediately analysed by a trained AI system. This system isn’t just looking at the obvious features of the retina; it is trained to assess everything the human eye can see, as well as the things the human eye can’t see. Some of these characteristics are as follows:</p>
<ul>
<li><p><strong>Vessel Caliber and Tortuosity</strong>: AI accurately measures the diameter and shape of the blood vessels, which can be indicators of cardiovascular risk, diabetes, and other systemic conditions.</p></li>
<li><p><strong>Layer Thickness</strong>: The deep learning model is capable of analysing the thickness of different retinal layers, and any changes of those thicknesses over time or compared to a healthy population. Subtle differences in layers are often correlated with various diseases or risks of developing them.</p></li>
<li><p><strong>Presence of Lesions</strong>: AI can automatically identify various abnormal lesions such as drusen, hemorrhages and exudates, often signs of eye disease and also correlated with systemic disease.</p></li>
<li><p><strong>Color Changes</strong>: AI can detect subtle changes in the colour of the retina, which may indicate underlying conditions related to blood flow and metabolism.</p></li>
<li><p><strong>Spatial Organization of Features</strong>: Deep learning networks can discern patterns of how different features are spatially organized and how those patterns might be related to specific conditions, going beyond the assessment of single features alone.</p></li>
<li><p><strong>Combinations of Features</strong>: The AI models are trained to evaluate combinations of features, just like clinicians do, in order to arrive at a final diagnostic or risk evaluation. This approach takes advantage of the redundancy of the retinal features, and is more robust than relying on single features alone.</p></li>
</ul>
<div class="callout callout-style-default callout-note callout-titled" title="Understanding the Process">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Understanding the Process
</div>
</div>
<div class="callout-body-container callout-body">
<p>When using the Opticare camera, you should keep the following in mind:</p>
<ul>
<li><p>Image Capture: A high-resolution fundus photograph of the retina is captured using a specialized camera and lighting.</p></li>
<li><p>Automated Analysis: This image is fed into our deep learning system which analyzes over 30 million retinal images during training.</p></li>
<li><p>Interpretation and Insights: The system provides an assessment of the retina as a marker for various diseases, and also generates a prediction of the biological age. You will be able to see a score or a graph that displays the findings clearly and simply.</p></li>
<li><p>Clinical Context: The AI’s findings should be used as an adjunct to your current clinical assessment and within the context of the specific client, rather than being a standalone diagnostic tool. A human expert should also interpret the findings, to ensure the best level of care.</p></li>
</ul>
</div>
</div>
<p>Deep learning and AI are transforming the way we analyze fundus images. This technology empowers you to quickly identify subtle patterns that are not readily visible to the human eye. The Opticare AI fundus camera harnesses this power and provides a cutting-edge means for you to offer comprehensive and state-of-the-art health assessments to your clients. By bridging the gap between the complexity of retinal data and readily interpretable results, Opticare brings a new level of clarity, insight and value to your wellness practice.</p>
</section>
<section id="retinal-imaging-cardiovascular-health-a-deep-connection" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="retinal-imaging-cardiovascular-health-a-deep-connection"><span class="header-section-number">2.4</span> Retinal Imaging &amp; Cardiovascular Health: A Deep Connection</h2>
<p>The human eye, often regarded as a window to the soul, increasingly appears to be a sophisticated mirror reflecting the overall health of the circulatory system. Within the retina, a delicate network of blood vessels—arterioles and venules—provides a unique, non-invasive opportunity to observe systemic vascular health. These microvessels, readily visible via non-mydriatic fundus photography, undergo subtle yet significant changes that are correlated with the increased risk of developing ischemic cardiovascular disease (ICVD). These changes, which include but are not limited to variations in arteriolar diameter, venular dilation, and the presence of microvascular damage, all indicate an underlying dysfunction within the body’s broader vascular system. In this section, we will explore the growing evidence linking retinal microvasculature and ICVD.</p>
<p>Traditional methods for assessing cardiovascular health, such as blood tests, blood pressure measurements, and questionnaires, provide essential but sometimes incomplete pictures of risk. These tests often require invasive procedures and/or complex interpretation and can be difficult to deploy at scale in community or primary care settings. Furthermore, risk assessment for CVD is still limited by the reliance on traditional risk factors, as many patients without these risk factors still develop heart disease. Retinal imaging, especially when combined with advanced image analysis and artificial intelligence (AI), offers a novel, non-invasive avenue for more direct and accessible assessment of a person’s vascular health and a tool that can be readily deployed in a wide range of clinical and community settings. One of the most compelling areas of research is the development of AI-driven approaches that are capable of predicting ICVD risk from retinal images, and these have shown remarkable performance in several large population studies.</p>
<p>One such study published in the <em>Science Bulletin</em> (<span class="citation" data-cites="ma_deep_2022">Ma et al. (<a href="references.html#ref-ma_deep_2022" role="doc-biblioref">2022</a>)</span>), details how researchers from China utilized a vast dataset of over 390,000 retinal images to train a deep-learning algorithm for ICVD risk stratification. This study was based on non-mydriatic fundus images which makes them easy to collect in most clinical environments. The algorithm was designed to estimate a patient’s 10-year risk of ICVD events by learning to identify patterns in fundus images that may not be apparent to the naked eye, such as subtle changes in microvasculature. The model performed exceptionally well in both internal and external validation datasets, demonstrating robustness and generalizability across different groups of people. The model achieved an impressive adjusted R² of 0.876 on an internal data set and 0.638 on the external validation set which is the Beijing Research on Ageing and Vessel (BRAVE) data set. The adjusted R2 represents the proportion of variability that could be explained with this model. An R2 of 1 suggests that the model perfectly predicts outcomes with no variance, while 0 represents a model with no power to predict outcomes. These results show that AI-driven assessment of retinal imaging has high potential to estimate ICVD risk.</p>
<p>Furthermore, when using the trained algorithm to classify the risk of ICVD, the model showed a very high area under the receiver operating characteristic (AUC) curve for detecting patients with a 10-year ICVD risk of ≥5%. The AUC was 0.971 (95% CI: 0.967-0.975) in the internal validation dataset and 0.859 (95% CI: 0.822-0.895) in external validation. For the higher threshold of ICVD risk (≥ 7.5%), the AUC was 0.976 (95% CI: 0.973-0.980) for the internal validation dataset, and 0.876 (95% CI: 0.816-0.937) for external data. An AUC value close to 1 indicates perfect diagnostic accuracy. These AUC values demonstrate the high predictive power of this algorithm, which is consistent with other studies that have also seen a high predictive power of AI algorithms based on fundus images. The results indicate that this algorithm may be a feasible and accurate alternative to established methods for assessing risk of ICVD, which may lead to wide scale implementation of retinal imaging in routine check-ups. The findings also show that AI algorithms are able to learn the association of microvascular changes with ICVD, including venular dilatation and arteriolar narrowing. AI can extract subtle relationships from images which, while difficult to appreciate with the naked eye, can be predictive of health outcomes. These subtle changes are also consistent with other traditional risk factors, like blood pressure.</p>
<p>The study’s authors noted a few limitations. First, the data was collected cross-sectionally, and their outcomes were predicted from an estimation tool that used traditional risk factors, rather than actual longitudinal ICVD event data. To confirm the prediction ability, a follow-up study of the BRAVE data is planned. Second, smoking status was absent in the dataset. Despite the limitations, the findings still provide compelling evidence of AI’s potential in ICVD risk assessment using retinal images, given the simplicity of the approach and the high degree of predictive power.</p>
</section>
<section id="retinal-imaging-cerebral-health-a-reflection-of-the-brain" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="retinal-imaging-cerebral-health-a-reflection-of-the-brain"><span class="header-section-number">2.5</span> Retinal Imaging &amp; Cerebral Health: A Reflection of the Brain</h2>
<p>The retina, during development, is an embryological extension of the brain, and as such shares an intimate physiological and anatomical relationship with it [15]. It’s an unusual tissue in that it can be observed non-invasively and allows an easy way to examine microvascular function. It is because of this that scientists are exploring the potential role of retinal imaging in understanding cerebrovascular and neurodegenerative diseases such as dementia. Retinal images provide a novel way to monitor cerebral health.</p>
<p>A growing body of research has established correlations between changes in the retinal vasculature and an increased risk of dementia. Studies have revealed that individuals with retinal microvascular abnormalities—including arteriolar narrowing, venular dilation, and the presence of retinopathy—have a higher likelihood of developing cognitive decline and dementia [9-11]. This link is rooted in the similarities between retinal and cerebral microvasculature. Both vascular systems share analogous structures and physiological functions, and changes in one may reflect similar pathological changes in the other. The implication of this relationship is important, because cerebrovascular disease is known to be a major contributor to dementia. Instead of solely relying on traditional cognitive tests, retinal imaging could be employed for population-wide screening, identifying high-risk patients earlier and allowing for earlier interventions.</p>
<p>In one innovative study, researchers developed a novel algorithm utilizing fundus photographs to estimate the Cardiovascular Risk Factors, Aging, and Incidence of Dementia (CAIDE) dementia risk score. The CAIDE is a well-established tool that uses a multidimensional risk factors (age, sex, educational level, physical inactivity, systolic blood pressure, total cholesterol, and body mass index) to predict the 20-year risk of dementia. The study showed that the algorithm had a high adjusted R2 (0.80 in internal validation and 0.58 in external validation) for predicted CAIDE risk score compared with the actual score, suggesting the algorithm was able to extract the relevant data in the retinal photos. Furthermore, the external validation of the algorithm revealed a high area under the receiver operating characteristic curve (AUC) of 0.926 (95% CI: 0.913–0.939), indicating strong ability to discriminate individuals with high dementia risk. This predictive ability is very impressive, as CAIDE scores have also shown to be predictive in a large multiethnic population.18-20 This study moves beyond simple correlation and demonstrates that AI-driven analysis of retinal images can predict complex metrics associated with dementia risk, indicating a path for non-invasive early detection and risk stratification.</p>
<p>Further supporting this connection between the retina and brain is work examining the impact of environmental factors on retinal structures. In a study, researchers at the University College London analyzed the UK Biobank data set, and determined that exposure to ambient air pollution may be linked to changes in retinal layer thicknesses [17]. They found that increased exposure to fine particulate matter (PM2.5) and nitrogen oxides were correlated with a thicker retinal nerve fiber layer (RNFL) and a thinner ganglion cell-inner plexiform layer (GCIPL). Moreover, higher levels of PM2.5 absorbance were associated with a thinner RNFL, inner nuclear layer, and OPL+ONL. These findings not only suggest the impact of environmental toxins on retinal structure, but imply that these same toxins might also cause similar changes in other areas, including the brain. Taken together, these investigations suggest that AI-based analysis of retinal images can potentially provide early, non-invasive indicators of brain health, providing a window into the pathological processes that may precede neurodegenerative conditions such as dementia.</p>
</section>
<section id="retinal-imaging-anemia-visualizing-blood-composition" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="retinal-imaging-anemia-visualizing-blood-composition"><span class="header-section-number">2.6</span> Retinal Imaging &amp; Anemia: Visualizing Blood Composition</h2>
<p>Beyond its role as a window into vascular and neurological health, the retina also offers a unique opportunity for non-invasive assessment of hematological conditions such as anemia. Anemia, characterized by a deficiency in red blood cells or hemoglobin, affects an estimated 1.6 billion individuals worldwide and presents significant challenges in its diagnosis and management [1,2]. Due to the invasiveness and cost of diagnostic tests that require blood samples, the condition is often left undiagnosed, particularly in resource limited settings. However, the recent advances in AI, particularly when applied to retinal fundus photographs, offer a promising alternative for non-invasive detection and management of this important condition [18].</p>
<p>Researchers have demonstrated that AI algorithms can accurately quantify hemoglobin (Hb) levels and detect the presence of anemia using fundus photos alone. In a large-scale study published in <em>Nature Biomedical Engineering</em>, a team of scientists used fundus images from the UK Biobank to develop deep learning models for the detection of anaemia using fundus photos, participant metadata or a combination of both [18]. They found that a combined model of fundus images with metadata was most accurate, and the study used a validation set of 11,388 study participants. The results of the combined model showed a mean absolute error (MAE) of 0.63 g/dL (95% CI, 0.62–0.64) in predicted Hb concentration, an AUC of 0.88 (95% CI, 0.86-0.89) for anaemia detection, an area under the ROC curve of 0.88 (95% confidence interval (CI) 0.86-0.89) for detection of any anemia, and an area under the ROC curve of 0.95 (95% CI, 0.93-0.97) for moderate to severe anemia. The MAE of 0.63 g/dl was close to the accuracy of laboratory measurements of 0.14 g/dl (ref) and much more accurate than non-invasive point-of-care devices, whose accuracy is 1.1 to 1.2 g/dl. These results are striking because these outcomes are based entirely on non-invasive measurements. The fundus photos capture the subtle changes associated with low haemoglobin, including pallor of the retina and venous tortuosity. These findings not only highlight the capabilities of deep learning in processing complex image data but also show a clear path for a non-invasive method of diagnosing anaemia.</p>
<p>Moreover, the study also found that that the algorithm could detect anaemia in a group of 539 participants with self-reported diabetes, with comparable performance. The study had a slightly larger MAE of 0.73 g/dl (95% CI, 0.68-0.78 g/dl) and an AUC of 0.89 (95% CI, 0.85-0.93), as compared to all participants in the study. These results are particularly relevant because anemia is frequently associated with diabetes (up to 23% of patients with diabetes remain undiagnosed for anaemia) and is shown to increase morbidity and mortality in these populations. Given the potential for regular retinal screening of diabetic retinopathy, the capability of AI to also detect anemia from retinal photos can be of immense use and provide additional opportunities for healthcare screening.</p>
</section>
<section id="retinal-imaging-for-prediction-of-age-and-mortality-risk" class="level2" data-number="2.7">
<h2 data-number="2.7" class="anchored" data-anchor-id="retinal-imaging-for-prediction-of-age-and-mortality-risk"><span class="header-section-number">2.7</span> Retinal Imaging for Prediction of Age and Mortality Risk</h2>
<p>While conventional wisdom might associate the retina solely with visual function, research is increasingly demonstrating that the eye also offers a window into the ageing process and a way to quantify mortality risk. The retina, composed of neural tissue and blood vessels, reflects both local changes that are influenced by age as well as the wider systemic effects of aging on the human body. Researchers have found that subtle age-related changes to the retina can be identified through fundus photography and quantified using AI, creating a novel biomarker of biological age and its connection with mortality risk.</p>
<p>A team of researchers in Singapore developed an algorithm that can estimate a patient’s biological age, termed RetiAGE, based on deep learning from fundus images (<span class="citation" data-cites="nusinovici_retinal_2022">Nusinovici et al. (<a href="references.html#ref-nusinovici_retinal_2022" role="doc-biblioref">2022</a>)</span>). The algorithm was initially trained on fundus photographs from 40,480 Korean adults and then evaluated using 56,301 participants of the UK Biobank, which demonstrated its generalizability across diverse populations and ethnicities. They found that, using a cut off of being equal or greater than 65 years of age, the algorithm showed an AUC of 0.76, with an AUPRC of 0.399. More importantly, they then stratified participants by their RetiAGE and followed them for over 10 years and found that individuals in the fourth quartile of RetiAGE had a 67% increased risk of all-cause mortality, 142% increased risk of CVD-related mortality, and 60% increased risk of cancer related mortality compared to those in the lowest quartile. Critically, these associations were independent of chronological age and of a number of established ageing biomarkers including albumin, creatinine, glucose and C-reactive protein. This data suggests the algorithm is capturing some of the biological changes associated with aging that conventional biomarkers do not identify. In this study, the researchers also showed that the addition of RetiAGE increased the ability to predict mortality risk beyond the conventional risk factors.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="_resources/images/RetiAgeMortality-Nusinovici.jpg" class="img-fluid figure-img"></p>
<figcaption>Retinal Age corresponds well with many other mortality metrics. Source: <span class="citation" data-cites="nusinovici_retinal_2022">Nusinovici et al. (<a href="references.html#ref-nusinovici_retinal_2022" role="doc-biblioref">2022</a>)</span></figcaption>
</figure>
</div>
<p>Similarly, another study based on a 10 year longitudinal analysis of fundus images from the UK Biobank found that the retinal age gap (difference between predicted and chronological age) was associated with a 2% increase in all-cause mortality risk and 3% increased risk of non-CVD/non-cancer mortality (<span class="citation" data-cites="zhu_retinal_2023">Zhu et al. (<a href="references.html#ref-zhu_retinal_2023" role="doc-biblioref">2023</a>)</span>). While they did not find a significant association between retinal age gap and CVD or cancer-related mortalities, their findings underscore a role of retinal changes in broader ageing processes. Both the above studies have strong statistical significance with large populations and rigorous methodology, thus supporting the hypothesis that retinal fundus imaging could offer a non-invasive means of determining both biological age and risk of mortality.</p>
<p>While the biological mechanisms underlying the observed retinal changes associated with age and mortality remain the subject of future study, it is becoming increasingly evident that AI-driven analysis of retinal images can provide novel markers of both biological ageing and long-term health outcomes, demonstrating significant potential as a tool to assess mortality risk in a range of different settings.</p>
</section>
<section id="a-growing-body-of-evidence-beyond-the-main-focus" class="level2" data-number="2.8">
<h2 data-number="2.8" class="anchored" data-anchor-id="a-growing-body-of-evidence-beyond-the-main-focus"><span class="header-section-number">2.8</span> A Growing Body of Evidence: Beyond The Main Focus</h2>
<p>The body of evidence supporting the use of fundus photography for general health assessment continues to grow, expanding beyond cardiovascular, neurological, and hematological conditions. AI is proving to be a versatile tool, and its capabilities in analyzing the complexity of retinal images are expanding our understanding of the retina and its link to a range of systemic diseases.</p>
<p>For example, diabetic retinopathy can be detected with high accuracy with the use of AI-based retinal imaging in clinical settings. A study published in <em>Ophthalmology</em> showed that deep learning systems could achieve excellent sensitivity and specificity, comparable to human experts for diabetic retinopathy detection [20], a common microvascular complication of diabetes. AI and retinal imaging is rapidly transforming diabetic retinopathy management, enabling scalable screening and early detection for disease prevention. The AI systems have also been used to help predict the progression of the retinopathy, which could allow clinicians to improve treatment strategies.</p>
<p>Glaucoma, another common ocular disease linked with various systemic factors, can also be identified by AI algorithms applied to fundus photos [21,22]. These findings may have clinical impact because glaucoma is a frequent cause of blindness and can potentially be screened and treated earlier. Beyond this, some researchers have explored the link between thyroid disease and retinal fundus images and have found promising applications for diagnostic purposes, though further work is required.</p>
<p>Future work in the field will no doubt bring further discovery and refinement of these techniques. Further research may uncover a spectrum of new correlations between subtle retinal features and various systemic conditions. The ongoing convergence of high-resolution imaging, big data analytics, and AI offers an exciting prospect for unlocking even more information about the human body from a simple, non-invasive retinal photograph.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-ma_deep_2022" class="csl-entry" role="listitem">
Ma, Yanjun, Jianhao Xiong, Yidan Zhu, Zongyuan Ge, Rong Hua, Meng Fu, Chenglong Li, et al. 2022. <span>“Deep Learning Algorithm Using Fundus Photographs for 10-Year Risk Assessment of Ischemic Cardiovascular Diseases in <span>China</span>.”</span> <em>Science Bulletin</em> 67 (1): 17–20. <a href="https://doi.org/10.1016/j.scib.2021.08.016">https://doi.org/10.1016/j.scib.2021.08.016</a>.
</div>
<div id="ref-nusinovici_retinal_2022" class="csl-entry" role="listitem">
Nusinovici, Simon, Tyler Hyungtaek Rim, Marco Yu, Geunyoung Lee, Yih-Chung Tham, Ning Cheung, Crystal Chun Yuen Chong, et al. 2022. <span>“Retinal Photograph-Based Deep Learning Predicts Biological Age, and Stratifies Morbidity and Mortality Risk.”</span> <em>Age and Ageing</em> 51 (4): afac065. <a href="https://doi.org/10.1093/ageing/afac065">https://doi.org/10.1093/ageing/afac065</a>.
</div>
<div id="ref-zhu_retinal_2023" class="csl-entry" role="listitem">
Zhu, Zhuoting, Danli Shi, Peng Guankai, Zachary Tan, Xianwen Shang, Wenyi Hu, Huan Liao, et al. 2023. <span>“Retinal Age Gap as a Predictive Biomarker for Mortality Risk.”</span> <em>British Journal of Ophthalmology</em> 107 (4): 547–54. <a href="https://doi.org/10.1136/bjophthalmol-2021-319807">https://doi.org/10.1136/bjophthalmol-2021-319807</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/opticareai\.github\.io\/eyes-on-health\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
          // default icon
          link.classList.add("external");
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./1-Chapter-Intro.html" class="pagination-link" aria-label="The Eye as a Window: Unveiling the Power of Retinal Imaging">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">The Eye as a Window: Unveiling the Power of Retinal Imaging</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./3-Chapter-Wellness.html" class="pagination-link" aria-label="Opticare AI – Marrying Innovation with Wellness">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Opticare AI – Marrying Innovation with Wellness</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>Copyright 2025 Opticare, Inc</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>
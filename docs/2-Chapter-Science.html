<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>2&nbsp; The Scientific Foundation: What the Evidence Reveals – Eyes on Health</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./3-Chapter-Wellness.html" rel="next">
<link href="./1-Chapter-Intro.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-e26003cea8cd680ca0c55a263523d882.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-5df17783e47628fdd0a009a58fb5d268.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="_resources/book/css/normalize.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./2-Chapter-Science.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">The Scientific Foundation: What the Evidence Reveals</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Eyes on Health</a> 
        <div class="sidebar-tools-main">
    <div class="dropdown">
      <a href="" title="Download" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Download"><i class="bi bi-download"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="./Eyes-on-Health.pdf">
              <i class="bi bi-file-pdf pe-1"></i>
            Download PDF
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="./Eyes-on-Health.epub">
              <i class="bi bi-journal pe-1"></i>
            Download ePub
            </a>
          </li>
      </ul>
    </div>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1-Chapter-Intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">The Eye as a Window: Unveiling the Power of Retinal Imaging</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2-Chapter-Science.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">The Scientific Foundation: What the Evidence Reveals</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3-Chapter-Wellness.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Opticare AI – Marrying Innovation with Wellness</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./4-Chapter-Practical.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Practical Applications in a Wellness Practice</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./5-Chapter-Guidebook.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Step-by-Step Guide to Using the Opticare Camera</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./6-Chapter-Faster.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Technology Moves Faster than Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./7-Chapter-Future.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">The Future of Retinal Imaging and AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./8-Chapter-Beyond.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Beyond the Eye – A Holistic Approach to Health</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./9-Chapter-Skepticism.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Addressing Skepticism and Setting Expectations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-Chapter-Final.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Embracing the Cutting Edge – A Call to Action</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Summary</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#retinal-imaging-cardiovascular-health-a-deep-connection" id="toc-retinal-imaging-cardiovascular-health-a-deep-connection" class="nav-link active" data-scroll-target="#retinal-imaging-cardiovascular-health-a-deep-connection"><span class="header-section-number">2.1</span> Retinal Imaging &amp; Cardiovascular Health: A Deep Connection</a></li>
  <li><a href="#retinal-imaging-cerebral-health-a-reflection-of-the-brain" id="toc-retinal-imaging-cerebral-health-a-reflection-of-the-brain" class="nav-link" data-scroll-target="#retinal-imaging-cerebral-health-a-reflection-of-the-brain"><span class="header-section-number">2.2</span> Retinal Imaging &amp; Cerebral Health: A Reflection of the Brain</a></li>
  <li><a href="#retinal-imaging-anemia-visualizing-blood-composition" id="toc-retinal-imaging-anemia-visualizing-blood-composition" class="nav-link" data-scroll-target="#retinal-imaging-anemia-visualizing-blood-composition"><span class="header-section-number">2.3</span> Retinal Imaging &amp; Anemia: Visualizing Blood Composition</a></li>
  <li><a href="#retinal-imaging-for-prediction-of-age-and-mortality-risk" id="toc-retinal-imaging-for-prediction-of-age-and-mortality-risk" class="nav-link" data-scroll-target="#retinal-imaging-for-prediction-of-age-and-mortality-risk"><span class="header-section-number">2.4</span> Retinal Imaging for Prediction of Age and Mortality Risk</a></li>
  <li><a href="#a-growing-body-of-evidence-beyond-the-main-focus" id="toc-a-growing-body-of-evidence-beyond-the-main-focus" class="nav-link" data-scroll-target="#a-growing-body-of-evidence-beyond-the-main-focus"><span class="header-section-number">2.5</span> A Growing Body of Evidence: Beyond The Main Focus</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">The Scientific Foundation: What the Evidence Reveals</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="retinal-imaging-cardiovascular-health-a-deep-connection" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="retinal-imaging-cardiovascular-health-a-deep-connection"><span class="header-section-number">2.1</span> Retinal Imaging &amp; Cardiovascular Health: A Deep Connection</h2>
<p>The human eye, often regarded as a window to the soul, increasingly appears to be a sophisticated mirror reflecting the overall health of the circulatory system. Within the retina, a delicate network of blood vessels—arterioles and venules—provides a unique, non-invasive opportunity to observe systemic vascular health. These microvessels, readily visible via non-mydriatic fundus photography, undergo subtle yet significant changes that are correlated with the increased risk of developing ischemic cardiovascular disease (ICVD). These changes, which include but are not limited to variations in arteriolar diameter, venular dilation, and the presence of microvascular damage, all indicate an underlying dysfunction within the body’s broader vascular system. In this section, we will explore the growing evidence linking retinal microvasculature and ICVD.</p>
<p>Traditional methods for assessing cardiovascular health, such as blood tests, blood pressure measurements, and questionnaires, provide essential but sometimes incomplete pictures of risk. These tests often require invasive procedures and/or complex interpretation and can be difficult to deploy at scale in community or primary care settings. Furthermore, risk assessment for CVD is still limited by the reliance on traditional risk factors, as many patients without these risk factors still develop heart disease. Retinal imaging, especially when combined with advanced image analysis and artificial intelligence (AI), offers a novel, non-invasive avenue for more direct and accessible assessment of a person’s vascular health and a tool that can be readily deployed in a wide range of clinical and community settings. One of the most compelling areas of research is the development of AI-driven approaches that are capable of predicting ICVD risk from retinal images, and these have shown remarkable performance in several large population studies.</p>
<p>One such study published in the <em>Science Bulletin</em> [1], details how researchers from China utilized a vast dataset of over 390,000 retinal images to train a deep-learning algorithm for ICVD risk stratification. This study was based on non-mydriatic fundus images which makes them easy to collect in most clinical environments. The algorithm was designed to estimate a patient’s 10-year risk of ICVD events by learning to identify patterns in fundus images that may not be apparent to the naked eye, such as subtle changes in microvasculature. The model performed exceptionally well in both internal and external validation datasets, demonstrating robustness and generalizability across different groups of people. The model achieved an impressive adjusted R² of 0.876 on an internal data set and 0.638 on the external validation set which is the Beijing Research on Ageing and Vessel (BRAVE) data set. The adjusted R2 represents the proportion of variability that could be explained with this model. An R2 of 1 suggests that the model perfectly predicts outcomes with no variance, while 0 represents a model with no power to predict outcomes. These results show that AI-driven assessment of retinal imaging has high potential to estimate ICVD risk.</p>
<p>Furthermore, when using the trained algorithm to classify the risk of ICVD, the model showed a very high area under the receiver operating characteristic (AUC) curve for detecting patients with a 10-year ICVD risk of ≥5%. The AUC was 0.971 (95% CI: 0.967-0.975) in the internal validation dataset and 0.859 (95% CI: 0.822-0.895) in external validation. For the higher threshold of ICVD risk (≥ 7.5%), the AUC was 0.976 (95% CI: 0.973-0.980) for the internal validation dataset, and 0.876 (95% CI: 0.816-0.937) for external data. An AUC value close to 1 indicates perfect diagnostic accuracy. These AUC values demonstrate the high predictive power of this algorithm, which is consistent with other studies that have also seen a high predictive power of AI algorithms based on fundus images. The results indicate that this algorithm may be a feasible and accurate alternative to established methods for assessing risk of ICVD, which may lead to wide scale implementation of retinal imaging in routine check-ups. The findings also show that AI algorithms are able to learn the association of microvascular changes with ICVD, including venular dilatation and arteriolar narrowing. AI can extract subtle relationships from images which, while difficult to appreciate with the naked eye, can be predictive of health outcomes. These subtle changes are also consistent with other traditional risk factors, like blood pressure.</p>
<p>The study’s authors noted a few limitations. First, the data was collected cross-sectionally, and their outcomes were predicted from an estimation tool that used traditional risk factors, rather than actual longitudinal ICVD event data. To confirm the prediction ability, a follow-up study of the BRAVE data is planned. Second, smoking status was absent in the dataset. Despite the limitations, the findings still provide compelling evidence of AI’s potential in ICVD risk assessment using retinal images, given the simplicity of the approach and the high degree of predictive power.</p>
</section>
<section id="retinal-imaging-cerebral-health-a-reflection-of-the-brain" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="retinal-imaging-cerebral-health-a-reflection-of-the-brain"><span class="header-section-number">2.2</span> Retinal Imaging &amp; Cerebral Health: A Reflection of the Brain</h2>
<p>The retina, during development, is an embryological extension of the brain, and as such shares an intimate physiological and anatomical relationship with it [15]. It’s an unusual tissue in that it can be observed non-invasively and allows an easy way to examine microvascular function. It is because of this that scientists are exploring the potential role of retinal imaging in understanding cerebrovascular and neurodegenerative diseases such as dementia. Retinal images provide a novel way to monitor cerebral health.</p>
<p>A growing body of research has established correlations between changes in the retinal vasculature and an increased risk of dementia. Studies have revealed that individuals with retinal microvascular abnormalities—including arteriolar narrowing, venular dilation, and the presence of retinopathy—have a higher likelihood of developing cognitive decline and dementia [9-11]. This link is rooted in the similarities between retinal and cerebral microvasculature. Both vascular systems share analogous structures and physiological functions, and changes in one may reflect similar pathological changes in the other. The implication of this relationship is important, because cerebrovascular disease is known to be a major contributor to dementia. Instead of solely relying on traditional cognitive tests, retinal imaging could be employed for population-wide screening, identifying high-risk patients earlier and allowing for earlier interventions.</p>
<p>In one innovative study, researchers developed a novel algorithm utilizing fundus photographs to estimate the Cardiovascular Risk Factors, Aging, and Incidence of Dementia (CAIDE) dementia risk score. The CAIDE is a well-established tool that uses a multidimensional risk factors (age, sex, educational level, physical inactivity, systolic blood pressure, total cholesterol, and body mass index) to predict the 20-year risk of dementia. The study showed that the algorithm had a high adjusted R2 (0.80 in internal validation and 0.58 in external validation) for predicted CAIDE risk score compared with the actual score, suggesting the algorithm was able to extract the relevant data in the retinal photos. Furthermore, the external validation of the algorithm revealed a high area under the receiver operating characteristic curve (AUC) of 0.926 (95% CI: 0.913–0.939), indicating strong ability to discriminate individuals with high dementia risk. This predictive ability is very impressive, as CAIDE scores have also shown to be predictive in a large multiethnic population.18-20 This study moves beyond simple correlation and demonstrates that AI-driven analysis of retinal images can predict complex metrics associated with dementia risk, indicating a path for non-invasive early detection and risk stratification.</p>
<p>Further supporting this connection between the retina and brain is work examining the impact of environmental factors on retinal structures. In a study, researchers at the University College London analyzed the UK Biobank data set, and determined that exposure to ambient air pollution may be linked to changes in retinal layer thicknesses [17]. They found that increased exposure to fine particulate matter (PM2.5) and nitrogen oxides were correlated with a thicker retinal nerve fiber layer (RNFL) and a thinner ganglion cell-inner plexiform layer (GCIPL). Moreover, higher levels of PM2.5 absorbance were associated with a thinner RNFL, inner nuclear layer, and OPL+ONL. These findings not only suggest the impact of environmental toxins on retinal structure, but imply that these same toxins might also cause similar changes in other areas, including the brain. Taken together, these investigations suggest that AI-based analysis of retinal images can potentially provide early, non-invasive indicators of brain health, providing a window into the pathological processes that may precede neurodegenerative conditions such as dementia.</p>
</section>
<section id="retinal-imaging-anemia-visualizing-blood-composition" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="retinal-imaging-anemia-visualizing-blood-composition"><span class="header-section-number">2.3</span> Retinal Imaging &amp; Anemia: Visualizing Blood Composition</h2>
<p>Beyond its role as a window into vascular and neurological health, the retina also offers a unique opportunity for non-invasive assessment of hematological conditions such as anemia. Anemia, characterized by a deficiency in red blood cells or hemoglobin, affects an estimated 1.6 billion individuals worldwide and presents significant challenges in its diagnosis and management [1,2]. Due to the invasiveness and cost of diagnostic tests that require blood samples, the condition is often left undiagnosed, particularly in resource limited settings. However, the recent advances in AI, particularly when applied to retinal fundus photographs, offer a promising alternative for non-invasive detection and management of this important condition [18].</p>
<p>Researchers have demonstrated that AI algorithms can accurately quantify hemoglobin (Hb) levels and detect the presence of anemia using fundus photos alone. In a large-scale study published in <em>Nature Biomedical Engineering</em>, a team of scientists used fundus images from the UK Biobank to develop deep learning models for the detection of anaemia using fundus photos, participant metadata or a combination of both [18]. They found that a combined model of fundus images with metadata was most accurate, and the study used a validation set of 11,388 study participants. The results of the combined model showed a mean absolute error (MAE) of 0.63 g/dL (95% CI, 0.62–0.64) in predicted Hb concentration, an AUC of 0.88 (95% CI, 0.86-0.89) for anaemia detection, an area under the ROC curve of 0.88 (95% confidence interval (CI) 0.86-0.89) for detection of any anemia, and an area under the ROC curve of 0.95 (95% CI, 0.93-0.97) for moderate to severe anemia. The MAE of 0.63 g/dl was close to the accuracy of laboratory measurements of 0.14 g/dl (ref) and much more accurate than non-invasive point-of-care devices, whose accuracy is 1.1 to 1.2 g/dl. These results are striking because these outcomes are based entirely on non-invasive measurements. The fundus photos capture the subtle changes associated with low haemoglobin, including pallor of the retina and venous tortuosity. These findings not only highlight the capabilities of deep learning in processing complex image data but also show a clear path for a non-invasive method of diagnosing anaemia.</p>
<p>Moreover, the study also found that that the algorithm could detect anaemia in a group of 539 participants with self-reported diabetes, with comparable performance. The study had a slightly larger MAE of 0.73 g/dl (95% CI, 0.68-0.78 g/dl) and an AUC of 0.89 (95% CI, 0.85-0.93), as compared to all participants in the study. These results are particularly relevant because anemia is frequently associated with diabetes (up to 23% of patients with diabetes remain undiagnosed for anaemia) and is shown to increase morbidity and mortality in these populations. Given the potential for regular retinal screening of diabetic retinopathy, the capability of AI to also detect anemia from retinal photos can be of immense use and provide additional opportunities for healthcare screening.</p>
</section>
<section id="retinal-imaging-for-prediction-of-age-and-mortality-risk" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="retinal-imaging-for-prediction-of-age-and-mortality-risk"><span class="header-section-number">2.4</span> Retinal Imaging for Prediction of Age and Mortality Risk</h2>
<p>While conventional wisdom might associate the retina solely with visual function, research is increasingly demonstrating that the eye also offers a window into the ageing process and a way to quantify mortality risk. The retina, composed of neural tissue and blood vessels, reflects both local changes that are influenced by age as well as the wider systemic effects of aging on the human body. Researchers have found that subtle age-related changes to the retina can be identified through fundus photography and quantified using AI, creating a novel biomarker of biological age and its connection with mortality risk.</p>
<p>A team of researchers in Singapore developed an algorithm that can estimate a patient’s biological age, termed RetiAGE, based on deep learning from fundus images<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. The algorithm was initially trained on fundus photographs from 40,480 Korean adults and then evaluated using 56,301 participants of the UK Biobank, which demonstrated its generalizability across diverse populations and ethnicities. They found that, using a cut off of being equal or greater than 65 years of age, the algorithm showed an AUC of 0.76, with an AUPRC of 0.399. More importantly, they then stratified participants by their RetiAGE and followed them for over 10 years and found that individuals in the fourth quartile of RetiAGE had a 67% increased risk of all-cause mortality, 142% increased risk of CVD-related mortality, and 60% increased risk of cancer related mortality compared to those in the lowest quartile. Critically, these associations were independent of chronological age and of a number of established ageing biomarkers including albumin, creatinine, glucose and C-reactive protein. This data suggests the algorithm is capturing some of the biological changes associated with aging that conventional biomarkers do not identify. In this study, the researchers also showed that the addition of RetiAGE increased the ability to predict mortality risk beyond the conventional risk factors.</p>
<p>Similarly, another study based on a 10 year longitudinal analysis of fundus images from the UK Biobank found that the retinal age gap (difference between predicted and chronological age) was associated with a 2% increase in all-cause mortality risk and 3% increased risk of non-CVD/non-cancer mortality [19]. While they did not find a significant association between retinal age gap and CVD or cancer-related mortalities, their findings underscore a role of retinal changes in broader ageing processes. Both the above studies have strong statistical significance with large populations and rigorous methodology, thus supporting the hypothesis that retinal fundus imaging could offer a non-invasive means of determining both biological age and risk of mortality.</p>
<p>While the biological mechanisms underlying the observed retinal changes associated with age and mortality remain the subject of future study, it is becoming increasingly evident that AI-driven analysis of retinal images can provide novel markers of both biological ageing and long-term health outcomes, demonstrating significant potential as a tool to assess mortality risk in a range of different settings.</p>
</section>
<section id="a-growing-body-of-evidence-beyond-the-main-focus" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="a-growing-body-of-evidence-beyond-the-main-focus"><span class="header-section-number">2.5</span> A Growing Body of Evidence: Beyond The Main Focus</h2>
<p>The body of evidence supporting the use of fundus photography for general health assessment continues to grow, expanding beyond cardiovascular, neurological, and hematological conditions. AI is proving to be a versatile tool, and its capabilities in analyzing the complexity of retinal images are expanding our understanding of the retina and its link to a range of systemic diseases.</p>
<p>For example, diabetic retinopathy can be detected with high accuracy with the use of AI-based retinal imaging in clinical settings. A study published in <em>Ophthalmology</em> showed that deep learning systems could achieve excellent sensitivity and specificity, comparable to human experts for diabetic retinopathy detection [20], a common microvascular complication of diabetes. AI and retinal imaging is rapidly transforming diabetic retinopathy management, enabling scalable screening and early detection for disease prevention. The AI systems have also been used to help predict the progression of the retinopathy, which could allow clinicians to improve treatment strategies.</p>
<p>Glaucoma, another common ocular disease linked with various systemic factors, can also be identified by AI algorithms applied to fundus photos [21,22]. These findings may have clinical impact because glaucoma is a frequent cause of blindness and can potentially be screened and treated earlier. Beyond this, some researchers have explored the link between thyroid disease and retinal fundus images and have found promising applications for diagnostic purposes, though further work is required.</p>
<p>Future work in the field will no doubt bring further discovery and refinement of these techniques. Further research may uncover a spectrum of new correlations between subtle retinal features and various systemic conditions. The ongoing convergence of high-resolution imaging, big data analytics, and AI offers an exciting prospect for unlocking even more information about the human body from a simple, non-invasive retinal photograph.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-zhu_retinal_2023" class="csl-entry" role="listitem">
Zhu, Zhuoting, Danli Shi, Peng Guankai, Zachary Tan, Xianwen Shang, Wenyi Hu, Huan Liao, et al. 2023. <span>“Retinal Age Gap as a Predictive Biomarker for Mortality Risk.”</span> <em>British Journal of Ophthalmology</em> 107 (4): 547–54. <a href="https://doi.org/10.1136/bjophthalmol-2021-319807">https://doi.org/10.1136/bjophthalmol-2021-319807</a>.
</div>
</div>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p><span class="citation" data-cites="zhu_retinal_2023">Zhu et al. (<a href="references.html#ref-zhu_retinal_2023" role="doc-biblioref">2023</a>)</span><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/opticareai\.github\.io\/eyes-on-health\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
          // default icon
          link.classList.add("external");
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./1-Chapter-Intro.html" class="pagination-link" aria-label="The Eye as a Window: Unveiling the Power of Retinal Imaging">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">The Eye as a Window: Unveiling the Power of Retinal Imaging</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./3-Chapter-Wellness.html" class="pagination-link" aria-label="Opticare AI – Marrying Innovation with Wellness">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Opticare AI – Marrying Innovation with Wellness</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>Copyright 2025 Opticare, Inc</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>

@article{nusinovici_retinal_2022,
	title = {Retinal photograph-based deep learning predicts biological age, and stratifies morbidity and mortality risk},
	volume = {51},
	copyright = {https://creativecommons.org/licenses/by-nc/4.0/},
	issn = {0002-0729, 1468-2834},
	url = {https://academic.oup.com/ageing/article/doi/10.1093/ageing/afac065/6561972},
	doi = {10.1093/ageing/afac065},
	abstract = {Abstract
            
              Background
              ageing is an important risk factor for a variety of human pathologies. Biological age (BA) may better capture ageing-related physiological changes compared with chronological age (CA).
            
            
              Objective
              we developed a deep learning (DL) algorithm to predict BA based on retinal photographs and evaluated the performance of our new ageing marker in the risk stratification of mortality and major morbidity in general populations.
            
            
              Methods
              we first trained a DL algorithm using 129,236 retinal photographs from 40,480 participants in the Korean Health Screening study to predict the probability of age being ≥65 years (‘RetiAGE’) and then evaluated the ability of RetiAGE to stratify the risk of mortality and major morbidity among 56,301 participants in the UK Biobank. Cox proportional hazards model was used to estimate the hazard ratios (HRs).
            
            
              Results
              in the UK Biobank, over a 10-year follow up, 2,236 (4.0\%) died; of them, 636 (28.4\%) were due to cardiovascular diseases (CVDs) and 1,276 (57.1\%) due to cancers. Compared with the participants in the RetiAGE first quartile, those in the RetiAGE fourth quartile had a 67\% higher risk of 10-year all-cause mortality (HR = 1.67 [1.42–1.95]), a 142\% higher risk of CVD mortality (HR = 2.42 [1.69–3.48]) and a 60\% higher risk of cancer mortality (HR = 1.60 [1.31–1.96]), independent of CA and established ageing phenotypic biomarkers. Likewise, compared with the first quartile group, the risk of CVD and cancer events in the fourth quartile group increased by 39\% (HR = 1.39 [1.14–1.69]) and 18\% (HR = 1.18 [1.10–1.26]), respectively. The best discrimination ability for RetiAGE alone was found for CVD mortality (c-index = 0.70, sensitivity = 0.76, specificity = 0.55). Furthermore, adding RetiAGE increased the discrimination ability of the model beyond CA and phenotypic biomarkers (increment in c-index between 1 and 2\%).
            
            
              Conclusions
              the DL-derived RetiAGE provides a novel, alternative approach to measure ageing.},
	language = {en},
	number = {4},
	urldate = {2024-05-10},
	journal = {Age and Ageing},
	author = {Nusinovici, Simon and Rim, Tyler Hyungtaek and Yu, Marco and Lee, Geunyoung and Tham, Yih-Chung and Cheung, Ning and Chong, Crystal Chun Yuen and Da Soh, Zhi and Thakur, Sahil and Lee, Chan Joo and Sabanayagam, Charumathi and Lee, Byoung Kwon and Park, Sungha and Kim, Sung Soo and Kim, Hyeon Chang and Wong, Tien-Yin and Cheng, Ching-Yu},
	month = apr,
	year = {2022},
	pages = {afac065},
	file = {Full Text:/Users/sprague/Zotero/storage/8VKZX8V4/Nusinovici et al. - 2022 - Retinal photograph-based deep learning predicts bi.pdf:application/pdf},
}

@article{lin_application_2021,
	title = {Application of {Comprehensive} {Artificial} intelligence {Retinal} {Expert} ({CARE}) system: a national real-world evidence study},
	volume = {3},
	issn = {25897500},
	shorttitle = {Application of {Comprehensive} {Artificial} intelligence {Retinal} {Expert} ({CARE}) system},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2589750021000868},
	doi = {10.1016/S2589-7500(21)00086-8},
	language = {en},
	number = {8},
	urldate = {2024-05-10},
	journal = {The Lancet Digital Health},
	author = {Lin, Duoru and Xiong, Jianhao and Liu, Congxin and Zhao, Lanqin and Li, Zhongwen and Yu, Shanshan and Wu, Xiaohang and Ge, Zongyuan and Hu, Xinyue and Wang, Bin and Fu, Meng and Zhao, Xin and Wang, Xin and Zhu, Yi and Chen, Chuan and Li, Tao and Li, Yonghao and Wei, Wenbin and Zhao, Mingwei and Li, Jianqiao and Xu, Fan and Ding, Lin and Tan, Gang and Xiang, Yi and Hu, Yongcheng and Zhang, Ping and Han, Yu and Li, Ji-Peng Olivia and Wei, Lai and Zhu, Pengzhi and Liu, Yizhi and Chen, Weirong and Ting, Daniel S W and Wong, Tien Y and Chen, Yuzhong and Lin, Haotian},
	month = aug,
	year = {2021},
	pages = {e486--e495},
	file = {Full Text:/Users/sprague/Zotero/storage/VF9U3GTZ/Lin et al. - 2021 - Application of Comprehensive Artificial intelligen.pdf:application/pdf},
}

@misc{xia_generalizing_2024,
	title = {Generalizing to {Unseen} {Domains} in {Diabetic} {Retinopathy} with {Disentangled} {Representations}},
	url = {http://arxiv.org/abs/2406.06384},
	abstract = {Diabetic Retinopathy (DR), induced by diabetes, poses a significant risk of visual impairment. Accurate and effective grading of DR aids in the treatment of this condition. Yet existing models experience notable performance degradation on unseen domains due to domain shifts. Previous methods address this issue by simulating domain style through simple visual transformation and mitigating domain noise via learning robust representations. However, domain shifts encompass more than image styles. They overlook biases caused by implicit factors such as ethnicity, age, and diagnostic criteria. In our work, we propose a novel framework where representations of paired data from different domains are decoupled into semantic features and domain noise. The resulting augmented representation comprises original retinal semantics and domain noise from other domains, aiming to generate enhanced representations aligned with real-world clinical needs, incorporating rich information from diverse domains. Subsequently, to improve the robustness of the decoupled representations, class and domain prototypes are employed to interpolate the disentangled representations while data-aware weights are designed to focus on rare classes and domains. Finally, we devise a robust pixel-level semantic alignment loss to align retinal semantics decoupled from features, maintaining a balance between intra-class diversity and dense class features. Experimental results on multiple benchmarks demonstrate the effectiveness of our method on unseen domains. The code implementations are accessible on https://github.com/richard-peng-xia/DECO.},
	urldate = {2024-06-12},
	publisher = {arXiv},
	author = {Xia, Peng and Hu, Ming and Tang, Feilong and Li, Wenxue and Zheng, Wenhao and Ju, Lie and Duan, Peibo and Yao, Huaxiu and Ge, Zongyuan},
	month = jun,
	year = {2024},
	note = {arXiv:2406.06384 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/Users/sprague/Zotero/storage/G5CQEEZZ/Xia et al. - 2024 - Generalizing to Unseen Domains in Diabetic Retinop.pdf:application/pdf;arXiv.org Snapshot:/Users/sprague/Zotero/storage/JV6HAE5T/2406.html:text/html},
}

@article{nusinovici_application_2024,
	title = {Application of a deep-learning marker for morbidity and mortality prediction derived from retinal photographs: a cohort development and validation study},
	issn = {26667568},
	shorttitle = {Application of a deep-learning marker for morbidity and mortality prediction derived from retinal photographs},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2666756824000898},
	doi = {10.1016/S2666-7568(24)00089-8},
	language = {en},
	urldate = {2024-10-03},
	journal = {The Lancet Healthy Longevity},
	author = {Nusinovici, Simon and Rim, Tyler Hyungtaek and Li, Hengtong and Yu, Marco and Deshmukh, Mihir and Quek, Ten Cheer and Lee, Geunyoung and Chong, Crystal Chun Yuen and Peng, Qingsheng and Xue, Can Can and Zhu, Zhuoting and Chew, Emily Y and Sabanayagam, Charumathi and Wong, Tien-Yin and Tham, Yih-Chung and Cheng, Ching-Yu},
	month = sep,
	year = {2024},
	pages = {100593},
	file = {Full Text:/Users/sprague/Zotero/storage/NMQVMD3U/Nusinovici et al. - 2024 - Application of a deep-learning marker for morbidit.pdf:application/pdf},
}

@article{zhao_foundation_2024,
	title = {A foundation model for joint segmentation, detection and recognition of biomedical objects across nine modalities},
	issn = {1548-7091, 1548-7105},
	url = {https://www.nature.com/articles/s41592-024-02499-w},
	doi = {10.1038/s41592-024-02499-w},
	language = {en},
	urldate = {2024-11-19},
	journal = {Nature Methods},
	author = {Zhao, Theodore and Gu, Yu and Yang, Jianwei and Usuyama, Naoto and Lee, Ho Hin and Kiblawi, Sid and Naumann, Tristan and Gao, Jianfeng and Crabtree, Angela and Abel, Jacob and Moung-Wen, Christine and Piening, Brian and Bifulco, Carlo and Wei, Mu and Poon, Hoifung and Wang, Sheng},
	month = nov,
	year = {2024},
	keywords = {ai, airdoc, medical, healthtech},
	file = {Zhao et al. - 2024 - A foundation model for joint segmentation, detecti.pdf:/Users/sprague/Zotero/storage/LQ6GC6MY/Zhao et al. - 2024 - A foundation model for joint segmentation, detecti.pdf:application/pdf},
}

@article{milea_artificial_2020,
	title = {Artificial {Intelligence} to {Detect} {Papilledema} from {Ocular} {Fundus} {Photographs}},
	volume = {382},
	copyright = {http://www.nejmgroup.org/legal/terms-of-use.htm},
	issn = {0028-4793, 1533-4406},
	url = {http://www.nejm.org/doi/10.1056/NEJMoa1917130},
	doi = {10.1056/NEJMoa1917130},
	language = {en},
	number = {18},
	urldate = {2025-01-03},
	journal = {New England Journal of Medicine},
	author = {Milea, Dan and Najjar, Raymond P. and Jiang, Zhubo and Ting, Daniel and Vasseneix, Caroline and Xu, Xinxing and Aghsaei Fard, Masoud and Fonseca, Pedro and Vanikieti, Kavin and Lagrèze, Wolf A. and La Morgia, Chiara and Cheung, Carol Y. and Hamann, Steffen and Chiquet, Christophe and Sanda, Nicolae and Yang, Hui and Mejico, Luis J. and Rougier, Marie-Bénédicte and Kho, Richard and Tran, Thi H.C. and Singhal, Shweta and Gohier, Philippe and Clermont-Vignal, Catherine and Cheng, Ching-Yu and Jonas, Jost B. and Yu-Wai-Man, Patrick and Fraser, Clare L. and Chen, John J. and Ambika, Selvakumar and Miller, Neil R. and Liu, Yong and Newman, Nancy J. and Wong, Tien Y. and Biousse, Valérie},
	month = apr,
	year = {2020},
	pages = {1687--1695},
	file = {Full Text:/Users/sprague/Zotero/storage/L4XZPEWH/Milea et al. - 2020 - Artificial Intelligence to Detect Papilledema from.pdf:application/pdf},
}

@article{ma_deep_2022,
	title = {Deep learning algorithm using fundus photographs for 10-year risk assessment of ischemic cardiovascular diseases in {China}},
	volume = {67},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {20959273},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2095927321005995},
	doi = {10.1016/j.scib.2021.08.016},
	language = {en},
	number = {1},
	urldate = {2025-01-03},
	journal = {Science Bulletin},
	author = {Ma, Yanjun and Xiong, Jianhao and Zhu, Yidan and Ge, Zongyuan and Hua, Rong and Fu, Meng and Li, Chenglong and Wang, Bin and Dong, Li and Zhao, Xin and Chen, Jili and Rong, Ce and He, Chao and Chen, Yuzhong and Wang, Zhaohui and Wei, Wenbin and Xie, Wuxiang and Wu, Yangfeng},
	month = jan,
	year = {2022},
	pages = {17--20},
	file = {Submitted Version:/Users/sprague/Zotero/storage/4Y7TK9IN/Ma et al. - 2022 - Deep learning algorithm using fundus photographs f.pdf:application/pdf},
}

@article{zhu_retinal_2023,
	title = {Retinal age gap as a predictive biomarker for mortality risk},
	volume = {107},
	issn = {0007-1161, 1468-2079},
	url = {https://bjo.bmj.com/lookup/doi/10.1136/bjophthalmol-2021-319807},
	doi = {10.1136/bjophthalmol-2021-319807},
	abstract = {Aim
              To develop a deep learning (DL) model that predicts age from fundus images (retinal age) and to investigate the association between retinal age gap (retinal age predicted by DL model minus chronological age) and mortality risk.
            
            
              Methods
              A total of 80 169 fundus images taken from 46 969 participants in the UK Biobank with reasonable quality were included in this study. Of these, 19 200 fundus images from 11 052 participants without prior medical history at the baseline examination were used to train and validate the DL model for age prediction using fivefold cross-validation. A total of 35 913 of the remaining 35 917 participants had available mortality data and were used to investigate the association between retinal age gap and mortality.
            
            
              Results
              The DL model achieved a strong correlation of 0.81 (p{\textless}0·001) between retinal age and chronological age, and an overall mean absolute error of 3.55 years. Cox regression models showed that each 1 year increase in the retinal age gap was associated with a 2\% increase in risk of all-cause mortality (hazard ratio (HR)=1.02, 95\% CI 1.00 to 1.03, p=0.020) and a 3\% increase in risk of cause-specific mortality attributable to non-cardiovascular and non-cancer disease (HR=1.03, 95\% CI 1.00 to 1.05, p=0.041) after multivariable adjustments. No significant association was identified between retinal age gap and cardiovascular- or cancer-related mortality.
            
            
              Conclusions
              Our findings indicate that retinal age gap might be a potential biomarker of ageing that is closely related to risk of mortality, implying the potential of retinal image as a screening tool for risk stratification and delivery of tailored interventions.},
	language = {en},
	number = {4},
	urldate = {2025-01-03},
	journal = {British Journal of Ophthalmology},
	author = {Zhu, Zhuoting and Shi, Danli and Guankai, Peng and Tan, Zachary and Shang, Xianwen and Hu, Wenyi and Liao, Huan and Zhang, Xueli and Huang, Yu and Yu, Honghua and Meng, Wei and Wang, Wei and Ge, Zongyuan and Yang, Xiaohong and He, Mingguang},
	month = apr,
	year = {2023},
	pages = {547--554},
	file = {Submitted Version:/Users/sprague/Zotero/storage/3PKXW9PP/Zhu et al. - 2023 - Retinal age gap as a predictive biomarker for mort.pdf:application/pdf},
}

@article{mitani_detection_2019,
	title = {Detection of anaemia from retinal fundus images via deeplearning},
	volume = {4},
	issn = {2157-846X},
	url = {https://www.nature.com/articles/s41551-019-0487-z},
	doi = {10.1038/s41551-019-0487-z},
	language = {en},
	number = {1},
	urldate = {2025-01-03},
	journal = {Nature Biomedical Engineering},
	author = {Mitani, Akinori and Huang, Abigail and Venugopalan, Subhashini and Corrado, Greg S. and Peng, Lily and Webster, Dale R. and Hammel, Naama and Liu, Yun and Varadarajan, Avinash V.},
	month = dec,
	year = {2019},
	pages = {18--27},
	file = {Submitted Version:/Users/sprague/Zotero/storage/8M2T8SAS/Mitani et al. - 2019 - Detection of anaemia from retinal fundus images vi.pdf:application/pdf},
}

@article{hua_development_2022,
	title = {Development and validation of a deep learning algorithm based on fundus photographs for estimating the {CAIDE} dementia risk score},
	volume = {51},
	copyright = {https://academic.oup.com/journals/pages/open\_access/funder\_policies/chorus/standard\_publication\_model},
	issn = {0002-0729, 1468-2834},
	url = {https://academic.oup.com/ageing/article/doi/10.1093/ageing/afac282/6936402},
	doi = {10.1093/ageing/afac282},
	abstract = {Abstract
            
              Background
              the Cardiovascular Risk Factors, Aging, and Incidence of Dementia (CAIDE) dementia risk score is a recognised tool for dementia risk stratification. However, its application is limited due to the requirements for multidimensional information and fasting blood draw. Consequently, an effective and non-invasive tool for screening individuals with high dementia risk in large population-based settings is urgently needed.
            
            
              Methods
              a deep learning algorithm based on fundus photographs for estimating the CAIDE dementia risk score was developed and internally validated by a medical check-up dataset included 271,864 participants in 19 province-level administrative regions of China, and externally validated based on an independent dataset included 20,690 check-up participants in Beijing. The performance for identifying individuals with high dementia risk (CAIDE dementia risk score ≥ 10 points) was evaluated by area under the receiver operating curve (AUC) with 95\% confidence interval (CI).
            
            
              Results
              the algorithm achieved an AUC of 0.944 (95\% CI: 0.939–0.950) in the internal validation group and 0.926 (95\% CI: 0.913–0.939) in the external group, respectively. Besides, the estimated CAIDE dementia risk score derived from the algorithm was significantly associated with both comprehensive cognitive function and specific cognitive domains.
            
            
              Conclusions
              this algorithm trained via fundus photographs could well identify individuals with high dementia risk in a population setting. Therefore, it has the potential to be utilised as a non-invasive and more expedient method for dementia risk stratification. It might also be adopted in dementia clinical trials, incorporated as inclusion criteria to efficiently select eligible participants.},
	language = {en},
	number = {12},
	urldate = {2025-01-03},
	journal = {Age and Ageing},
	author = {Hua, Rong and Xiong, Jianhao and Li, Gail and Zhu, Yidan and Ge, Zongyuan and Ma, Yanjun and Fu, Meng and Li, Chenglong and Wang, Bin and Dong, Li and Zhao, Xin and Ma, Zhiqiang and Chen, Jili and Gao, Xinxiao and He, Chao and Wang, Zhaohui and Wei, Wenbin and Wang, Fei and Gao, Xiangyang and Chen, Yuzhong and Zeng, Qiang and Xie, Wuxiang},
	month = dec,
	year = {2022},
	pages = {afac282},
	file = {Full Text:/Users/sprague/Zotero/storage/E9ZIU4FN/Hua et al. - 2022 - Development and validation of a deep learning algo.pdf:application/pdf},
}

@article{chua_ambient_2020,
	title = {Ambient {Air} {Pollution} {Associations} with {Retinal} {Morphology} in the {UK} {Biobank}},
	volume = {61},
	copyright = {http://creativecommons.org/licenses/by/4.0/},
	issn = {1552-5783},
	url = {https://iovs.arvojournals.org/article.aspx?articleid=2766216},
	doi = {10.1167/iovs.61.5.32},
	language = {en},
	number = {5},
	urldate = {2025-01-03},
	journal = {Investigative Opthalmology \& Visual Science},
	author = {Chua, Sharon Y. L. and Khawaja, Anthony P. and Dick, Andrew D. and Morgan, James and Dhillon, Baljean and Lotery, Andrew J. and Strouthidis, Nicholas G. and Reisman, Charles and Peto, Tunde and Khaw, Peng T. and Foster, Paul J. and Patel, Praveen J. and {on behalf of The UK Biobank Eye and Vision Consortium}},
	month = may,
	year = {2020},
	pages = {32},
	file = {Full Text:/Users/sprague/Zotero/storage/LGD863RB/Chua et al. - 2020 - Ambient Air Pollution Associations with Retinal Mo.pdf:application/pdf},
}

@article{wong_retinal_2002,
	title = {Retinal {Arteriolar} {Narrowing} and {Risk} of {Diabetes} {Mellitus} in {Middle}-aged {Persons}},
	volume = {287},
	issn = {0098-7484},
	url = {http://jama.jamanetwork.com/article.aspx?doi=10.1001/jama.287.19.2528},
	doi = {10.1001/jama.287.19.2528},
	language = {en},
	number = {19},
	urldate = {2025-01-03},
	journal = {JAMA},
	author = {Wong, Tien Yin},
	month = may,
	year = {2002},
	pages = {2528},
}

@article{kivipelto_risk_2006,
	title = {Risk score for the prediction of dementia risk in 20 years among middle aged people: a longitudinal, population-based study},
	volume = {5},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {14744422},
	shorttitle = {Risk score for the prediction of dementia risk in 20 years among middle aged people},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1474442206705373},
	doi = {10.1016/S1474-4422(06)70537-3},
	language = {en},
	number = {9},
	urldate = {2025-01-05},
	journal = {The Lancet Neurology},
	author = {Kivipelto, Miia and Ngandu, Tiia and Laatikainen, Tiina and Winblad, Bengt and Soininen, Hilkka and Tuomilehto, Jaakko},
	month = sep,
	year = {2006},
	pages = {735--741},
	file = {Kivipelto et al. - 2006 - Risk score for the prediction of dementia risk in .pdf:/Users/sprague/Zotero/storage/7J9BG6IJ/Kivipelto et al. - 2006 - Risk score for the prediction of dementia risk in .pdf:application/pdf},
}

@article{tsukahara_is_2021,
	title = {Is baseline pupil size related to cognitive ability? {Yes} (under proper lighting conditions)},
	volume = {211},
	issn = {00100277},
	shorttitle = {Is baseline pupil size related to cognitive ability?},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0010027721000627},
	doi = {10.1016/j.cognition.2021.104643},
	language = {en},
	urldate = {2025-01-25},
	journal = {Cognition},
	author = {Tsukahara, Jason S. and Engle, Randall W.},
	month = jun,
	year = {2021},
	pages = {104643},
}

@article{cheung_retinal_2014,
	title = {Retinal {Microvasculature} in {Alzheimer}'s {Disease}},
	volume = {42},
	issn = {18758908, 13872877},
	url = {https://journals.sagepub.com/doi/full/10.3233/JAD-141596},
	doi = {10.3233/JAD-141596},
	number = {s4},
	urldate = {2025-03-18},
	journal = {Journal of Alzheimer's Disease},
	author = {Cheung, Carol Yim-lui and Ong, Yi-Ting and Ikram, M. Kamran and Chen, Christopher and Wong, Tien Yin},
	editor = {De La Torre, Jack C.},
	month = oct,
	year = {2014},
	pages = {S339--S352},
}
